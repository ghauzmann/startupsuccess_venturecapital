{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing relevant libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import pickle\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV\n",
    "from sklearn.metrics import precision_score, recall_score,\\\n",
    "precision_recall_curve, f1_score, fbeta_score,\\\n",
    "accuracy_score, confusion_matrix, roc_auc_score, roc_curve, ConfusionMatrixDisplay\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import svm\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from scipy.sparse import hstack\n",
    "from sklearn import preprocessing\n",
    "from sklearn.utils import resample, shuffle\n",
    "from imblearn.over_sampling import ADASYN, SMOTE\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading datasets as pickle\n",
    "\n",
    "#with open(\"data/clean_eu.pickle\", 'rb') as eu:\n",
    "#    eu_df = pickle.load(eu)\n",
    "    \n",
    "#with open(\"data/clean_us.pickle\", 'rb') as us:\n",
    "#    us_df = pickle.load(us)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading datasets as csv\n",
    "\n",
    "eu_df = pd.read_csv(\"data/clean_eu.csv\")\n",
    "us_df = pd.read_csv(\"data/clean_us.csv\")\n",
    "\n",
    "# Dropping \"status\" column in both datasets as target boolean \"label\" took over \n",
    "# to indicate whether successful or not\n",
    "# Also dropping \"first_funding_at\" and \"last_funding_at\" as well as a random column\n",
    "# \"Unnamed: 0\"\n",
    "\n",
    "eu_df = eu_df.drop([\"status\", \"first_funding_at\", \"last_funding_at\"], 1)\n",
    "eu_df = eu_df.drop(columns=eu_df.columns[0])\n",
    "\n",
    "us_df = us_df.drop([\"status\", \"first_funding_at\", \"last_funding_at\"], 1)\n",
    "us_df = us_df.drop(columns=us_df.columns[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eu_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count target values EU\n",
    "target_count =  eu_df['label'].value_counts()\n",
    "\n",
    "# Printing class balance\n",
    "print(f'Class 0: {target_count[0]}')\n",
    "print(f'Class 1: {target_count[1]}')\n",
    "print(f'Proportion: {round(target_count[0] / target_count[1], 2)} : 1')\n",
    "#print('Percentage of Majority Class: {:f}'.format(\n",
    "#    round(target_count[0] / sum(target_count), 4) * 100))\n",
    "\n",
    "# Count target values US\n",
    "target_count = us_df['label'].value_counts()\n",
    "\n",
    "# Printing class balance\n",
    "print(\"\\n\")\n",
    "print(f'Class 0: {target_count[0]}')\n",
    "print(f'Class 1: {target_count[1]}')\n",
    "print(f'Proportion: {round(target_count[0] / target_count[1], 2)} : 1')\n",
    "#print('Percentage of Majority Class: {:f}'.format(\n",
    "#    round(target_count[0] / sum(target_count), 4) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle and split EU dataset into train and test\n",
    "X_eu = eu_df.drop(columns=['label'])\n",
    "y_eu = eu_df['label']\n",
    "X_train_eu, X_test_eu, y_train_eu, y_test_eu = train_test_split(X_eu, \n",
    "                                                                 y_eu, test_size=0.25, \n",
    "                                                                 random_state=42,\n",
    "                                                                 stratify=y_eu, shuffle=True)\n",
    "# Splitting further into EU validation set\n",
    "#X_val_eu, X_test_eu, y_val_eu, y_test_eu = train_test_split(X_test_eu, \n",
    "#                                                                 y_test_eu, test_size=0.5, \n",
    "#                                                                 random_state=42)\n",
    "\n",
    "# Shuffle and split US dataset into train and test\n",
    "X_us = us_df.drop(columns=['label'])\n",
    "y_us = us_df['label']\n",
    "X_train_us, X_test_us, y_train_us, y_test_us = train_test_split(X_us, \n",
    "                                                                 y_us, test_size=0.25, \n",
    "                                                                 random_state=42,\n",
    "                                                                 stratify=y_us, shuffle=True)\n",
    "\n",
    "# Splitting further into US validation set\n",
    "#X_val_us, X_test_us, y_val_us, y_test_us = train_test_split(X_test_us, \n",
    "#                                                                 y_test_us, test_size=0.5, \n",
    "#                                                                 random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"X_eu shape:\", X_eu.shape)\n",
    "print(\"X_train_eu shape:\", X_train_eu.shape)\n",
    "print(\"X_test_eu shape:\", X_test_eu.shape)\n",
    "#print(\"X_val_eu shape:\", X_val_eu.shape)\n",
    "\n",
    "print(\"\\nX_us shape:\", X_us.shape)\n",
    "print(\"X_train_us shape:\", X_train_us.shape)\n",
    "print(\"X_test_us shape:\", X_test_us.shape)\n",
    "#print(\"X_val_us shape:\", X_val_us.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''# Upsampling minority class\n",
    "\n",
    "# Separate majority and minority classes\n",
    "X_train_eu['label'] = y_train_eu\n",
    "X_train_us['label'] = y_train_us\n",
    "\n",
    "#EU\n",
    "eu_minority = X_train_eu[X_train_eu.label==0]\n",
    "eu_majority = X_train_eu[X_train_eu.label==1]\n",
    "\n",
    "# n is the number of majority class (label = 1)\n",
    "n = X_train_eu.label.value_counts()[1]\n",
    "\n",
    "# Upsample minority class\n",
    "eu_minority_upsampled = resample(eu_minority, \n",
    "                                 replace=True,     # sample with replacement\n",
    "                                 n_samples=n,    # to match majority class\n",
    "                                 random_state=123) # reproducible results\n",
    "\n",
    "# Combine majority class with upsampled minority class\n",
    "eu_upsampled = pd.concat([eu_majority, eu_minority_upsampled])\n",
    "eu_upsampled = shuffle(eu_upsampled)\n",
    "\n",
    "\n",
    "#US\n",
    "us_minority = X_train_us[X_train_us.label==0]\n",
    "us_majority = X_train_us[X_train_us.label==1]\n",
    "\n",
    "# n is the number of majority class (label = 1)\n",
    "n = X_train_us.label.value_counts()[1]\n",
    "\n",
    "# Upsample minority class\n",
    "us_minority_upsampled = resample(us_minority, \n",
    "                                 replace=True,     # sample with replacement\n",
    "                                 n_samples=n,    # to match majority class\n",
    "                                 random_state=123) # reproducible results\n",
    "\n",
    "# Combine majority class with upsampled minority class\n",
    "us_upsampled = pd.concat([us_majority, us_minority_upsampled])\n",
    "us_upsampled = shuffle(us_upsampled)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''# EU seperating X y\n",
    "X_train_eu = eu_upsampled.drop(columns=['label'])\n",
    "y_train_eu = eu_upsampled['label']\n",
    "\n",
    "# US seperating X y\n",
    "X_train_us = us_upsampled.drop(columns=['label'])\n",
    "y_train_us = us_upsampled['label']'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count target values EU Post train/test split\n",
    "target_count_upsampled = y_train_eu.value_counts()\n",
    "\n",
    "# Printing class balance\n",
    "print(f'Class 0: {target_count_upsampled[0]}')\n",
    "print(f'Class 1: {target_count_upsampled[1]}')\n",
    "print(f'Proportion: {round(target_count_upsampled[0] / target_count_upsampled[1], 2)} : 1')\n",
    "print('Percentage of Majority Class: {:f}'.format(\n",
    "    round(target_count_upsampled[0] / sum(target_count_upsampled), 4) * 100))\n",
    "\n",
    "# Count target values US\n",
    "target_count_upsampled_us = y_train_us.value_counts()\n",
    "\n",
    "# Printing class balance\n",
    "print(\"\\n\")\n",
    "print(f'Class 0: {target_count_upsampled_us[0]}')\n",
    "print(f'Class 1: {target_count_upsampled_us[1]}')\n",
    "print(f'Proportion: {round(target_count_upsampled_us[0] / target_count_upsampled_us[1], 2)} : 1')\n",
    "print('Percentage of Majority Class: {:f}'.format(\n",
    "    round(target_count_upsampled_us[0] / sum(target_count_upsampled_us), 4) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_us.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seperating 4 types of features EU\n",
    "X_train_industry_eu = X_train_eu.industry\n",
    "X_train_country_eu = X_train_eu.country_code\n",
    "X_train_city_eu = X_train_eu.city\n",
    "X_train_eu_nums = X_train_eu.drop(columns=[\"industry\", \"country_code\", \"city\"])\n",
    "\n",
    "X_test_industry_eu = X_train_eu.industry\n",
    "X_test_country_eu = X_test_eu.country_code\n",
    "X_test_city_eu = X_test_eu.city\n",
    "X_test_eu_nums = X_test_eu.drop(columns=[\"industry\", \"country_code\", \"city\"])\n",
    "\n",
    "# Seperating 4 types of features US\n",
    "X_train_industry_us = X_train_us.industry\n",
    "X_train_state_us = X_train_us.state_code\n",
    "X_train_region_us = X_train_us.region\n",
    "X_train_us_nums = X_train_us.drop(columns=[\"industry\", \"state_code\", \"region\"])\n",
    "\n",
    "X_test_industry_us = X_train_us.industry\n",
    "X_test_state_us = X_test_us.state_code\n",
    "X_test_region_us = X_test_us.region\n",
    "X_test_us_nums = X_test_us.drop(columns=[\"industry\", \"state_code\", \"region\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature encoding EU\n",
    "\n",
    "# Encoding text feature - industry\n",
    "X_train_eu.industry = X_train_eu.industry.astype(str)\n",
    "vectorizer_industry = CountVectorizer(min_df=5)\n",
    "vectorizer_industry.fit(X_train_eu.industry)\n",
    "\n",
    "X_train_industry_eu = vectorizer_industry.transform(X_train_eu.industry)\n",
    "X_test_industry_eu = vectorizer_industry.transform(X_test_eu.industry)\n",
    "\n",
    "\n",
    "# Encoding categorical feature - country\n",
    "X_train_eu.country_code = X_train_eu.country_code.astype(str)\n",
    "vectorizer_country = CountVectorizer(min_df=1)\n",
    "vectorizer_country.fit(X_train_eu.country_code)\n",
    "\n",
    "X_train_country_eu = vectorizer_country.transform(X_train_eu.country_code)\n",
    "X_test_country_eu = vectorizer_country.transform(X_test_eu.country_code)\n",
    "\n",
    "\n",
    "# Encoding categorical feature - city\n",
    "X_train_eu.city = X_train_eu.city.astype(str)\n",
    "vectorizer_city = CountVectorizer(min_df=1)\n",
    "vectorizer_city.fit(X_train_eu.city)\n",
    "\n",
    "X_train_city_eu = vectorizer_city.transform(X_train_eu.city)\n",
    "X_test_city_eu = vectorizer_city.transform(X_test_eu.city)\n",
    "\n",
    "\n",
    "\n",
    "# Feature encoding US\n",
    "# Encoding text feature - industry\n",
    "X_train_us.industry = X_train_us.industry.astype(str)\n",
    "vectorizer_industry_us = CountVectorizer(min_df=5)\n",
    "vectorizer_industry_us.fit(X_train_us.industry)\n",
    "\n",
    "X_train_industry_us = vectorizer_industry_us.transform(X_train_us.industry)\n",
    "X_test_industry_us = vectorizer_industry_us.transform(X_test_us.industry)\n",
    "\n",
    "\n",
    "# Encoding categorical feature - state\n",
    "X_train_us.state_code = X_train_us.state_code.astype(str)\n",
    "vectorizer_state = CountVectorizer(min_df=1)\n",
    "vectorizer_state.fit(X_train_us.state_code)\n",
    "\n",
    "X_train_state_us = vectorizer_state.transform(X_train_us.state_code)\n",
    "X_test_state_us = vectorizer_state.transform(X_test_us.state_code)\n",
    "\n",
    "\n",
    "# Encoding categorical feature - region\n",
    "X_train_us.region = X_train_us.region.astype(str)\n",
    "vectorizer_region = CountVectorizer(min_df=1)\n",
    "vectorizer_region.fit(X_train_us.region)\n",
    "\n",
    "X_train_region_us = vectorizer_region.transform(X_train_us.region)\n",
    "X_test_region_us = vectorizer_region.transform(X_test_us.region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_industry_eu.toarray()\n",
    "X_train_industry_us.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling Features\n",
    "scaler_eu = preprocessing.StandardScaler()\n",
    "scaler_us = preprocessing.StandardScaler()\n",
    "\n",
    "# EU\n",
    "X_train_eu_nums_scaled = scaler_eu.fit_transform(X_train_eu_nums)\n",
    "X_test_eu_nums_scaled = scaler_eu.transform(X_test_eu_nums)\n",
    "\n",
    "# US\n",
    "X_train_us_nums_scaled = scaler_us.fit_transform(X_train_us_nums)\n",
    "X_test_us_nums_scaled = scaler_us.transform(X_test_us_nums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_city_eu.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatinating inputs into a single input X for classifiers\n",
    "\n",
    "# EU\n",
    "X_train_eu_full = hstack([X_train_eu_nums_scaled, X_train_country_eu, X_train_city_eu, X_train_industry_eu])\n",
    "X_test_eu_full = hstack([X_test_eu_nums_scaled, X_test_country_eu, X_test_city_eu, X_test_industry_eu])\n",
    "\n",
    "#X_train_eu_full = np.concatenate((X_train_eu_nums_scaled, X_train_country_eu, X_train_city_eu, X_train_industry_eu), axis=1)\n",
    "#X_test_eu_full = np.concatenate((X_test_eu_nums_scaled, X_test_country_eu, X_test_city_eu, X_test_industry_eu), axis=1)\n",
    "\n",
    "\n",
    "# US\n",
    "X_train_us_full = hstack([X_train_us_nums_scaled, X_train_state_us, X_train_region_us, X_train_industry_us])\n",
    "X_test_us_full = hstack([X_test_us_nums_scaled, X_test_state_us, X_test_region_us, X_test_industry_us])\n",
    "\n",
    "#X_train_us_full = np.concatenate((X_train_us_nums_scaled, X_train_state_us, X_train_region_us, X_train_industry_us), axis=1)\n",
    "#X_test_us_full = np.concatenate((X_test_us_nums_scaled, X_test_state_us, X_test_region_us, X_test_industry_us), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Oversamling with ADASYN\n",
    "ada = ADASYN(random_state=42)\n",
    "\n",
    "# EU\n",
    "X_train_eu_full, y_train_eu = ada.fit_resample(X_train_eu_full, y_train_eu)\n",
    "\n",
    "# US\n",
    "X_train_us_full, y_train_us = ada.fit_resample(X_train_us_full, y_train_us)\n",
    "\n",
    "# Experimenting with SMOTE Oversampling\n",
    "smote = SMOTE(random_state=42)\n",
    "\n",
    "# EU\n",
    "#X_train_eu_full, y_train_eu = smote.fit_resample(X_train_eu_full, y_train_eu)\n",
    "\n",
    "# US\n",
    "#X_train_us_full, y_train_us = smote.fit_resample(X_train_us_full, y_train_us)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count target values EU Post upsampling\n",
    "target_count_upsampled = y_train_eu.value_counts()\n",
    "\n",
    "# Printing class balance\n",
    "print(f'Class 0: {target_count_upsampled[0]}')\n",
    "print(f'Class 1: {target_count_upsampled[1]}')\n",
    "print(f'Proportion: {round(target_count_upsampled[0] / target_count_upsampled[1], 2)} : 1')\n",
    "print('Percentage of Majority Class: {:f}'.format(\n",
    "    round(target_count_upsampled[0] / sum(target_count_upsampled), 4) * 100))\n",
    "\n",
    "# Count target values US\n",
    "target_count_upsampled_us = y_train_us.value_counts()\n",
    "\n",
    "# Printing class balance\n",
    "print(\"\\n\")\n",
    "print(f'Class 0: {target_count_upsampled_us[0]}')\n",
    "print(f'Class 1: {target_count_upsampled_us[1]}')\n",
    "print(f'Proportion: {round(target_count_upsampled_us[0] / target_count_upsampled_us[1], 2)} : 1')\n",
    "print('Percentage of Majority Class: {:f}'.format(\n",
    "    round(target_count_upsampled_us[0] / sum(target_count_upsampled_us), 4) * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove warnings in output\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# GridSearch, Cross-validation and Model Tuning to pick best model parameters\n",
    "\n",
    "# Stratified KFold\n",
    "#EU\n",
    "cv_eu = StratifiedKFold(n_splits=5).split(X_train_eu_full, y_train_eu)\n",
    "\n",
    "#US\n",
    "cv_us = StratifiedKFold( n_splits=5).split(X_train_us_full, y_train_us)\n",
    "\n",
    "\n",
    "# EU\n",
    "\n",
    "# LogReg\n",
    "lr_eu_grid = LogisticRegression()\n",
    "\n",
    "grid_lr_eu_values = {'penalty': ['none', 'elasticnet', 'l1', 'l2'],\n",
    "                     'C':[0.001, 0.01, 0.1, 1, 10, 100], \n",
    "                     'solver': ['lbfgs', 'liblinear']}\n",
    "\n",
    "grid_lr_eu = GridSearchCV(estimator = lr_eu_grid, \n",
    "                          param_grid = grid_lr_eu_values, \n",
    "                          scoring = 'recall', \n",
    "                          cv=cv_eu)\n",
    "\n",
    "grid_lr_eu.fit(X_train_eu_full, y_train_eu)\n",
    "\n",
    "print(\"EU LogReg best parameters:\", grid_lr_eu.best_params_)\n",
    "\n",
    "y_pred_lr_eu_grid = grid_lr_eu.predict(X_test_eu_full)\n",
    "\n",
    "acc_lr_eu_grid = accuracy_score(y_test_eu, y_pred_lr_eu_grid)\n",
    "f1_lr_eu_grid = f1_score(y_test_eu, y_pred_lr_eu_grid)\n",
    "fb_lr_eu_grid = fbeta_score(y_test_eu, y_pred_lr_eu_grid, beta=3)\n",
    "\n",
    "print(\"Logistic Regression EU Accuracy: \", acc_lr_eu_grid)\n",
    "print(\"Logistic Regression EU f1 Score: \", f1_lr_eu_grid)\n",
    "print(\"Logistic Regression EU f-beta Score: \", fb_lr_eu_grid)\n",
    "\n",
    "# Calculating ROC curve for EU LogReg Grid\n",
    "fpr_lr_eu_grid, tpr_lr_eu_grid, thresholds_lr_eu_grid = roc_curve(\n",
    "    y_test_eu, grid_lr_eu.predict_proba(X_test_eu_full)[:, 1])\n",
    "\n",
    "\n",
    "# Calculating area under the curve (AUC) for ROC for EU LogReg Grid\n",
    "auc_lr_eu_grid = roc_auc_score(y_test_eu, grid_lr_eu.predict_proba(X_test_eu_full)[:, 1])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# US\n",
    "\n",
    "# LogReg\n",
    "lr_us_grid = LogisticRegression()\n",
    "\n",
    "grid_lr_us_values = {'penalty': ['none', 'elasticnet', 'l1', 'l2'],\n",
    "                     'C':[0.001, 0.01, 0.1, 1, 10, 100], \n",
    "                     'solver': ['lbfgs', 'liblinear']}\n",
    "\n",
    "grid_lr_us = GridSearchCV(estimator = lr_us_grid, \n",
    "                          param_grid = grid_lr_us_values, \n",
    "                          scoring = 'recall', \n",
    "                          cv=cv_us)\n",
    "\n",
    "grid_lr_us.fit(X_train_us_full, y_train_us)\n",
    "\n",
    "print(\"US LogReg best parameters:\", grid_lr_us.best_params_)\n",
    "\n",
    "y_pred_lr_us_grid = grid_lr_us.predict(X_test_us_full)\n",
    "\n",
    "acc_lr_us_grid = accuracy_score(y_test_us, y_pred_lr_us_grid)\n",
    "f1_lr_us_grid = f1_score(y_test_us, y_pred_lr_us_grid)\n",
    "fb_lr_us_grid = fbeta_score(y_test_us, y_pred_lr_us_grid, beta=3)\n",
    "\n",
    "print(\"Logistic Regression US Accuracy: \", acc_lr_us_grid)\n",
    "print(\"Logistic Regression US f1 Score: \", f1_lr_us_grid)\n",
    "print(\"Logistic Regression US f-beta Score: \", fb_lr_us_grid)\n",
    "\n",
    "# Calculating ROC curve for US LogReg Grid\n",
    "fpr_lr_us_grid, tpr_lr_us_grid, thresholds_lr_us_grid = roc_curve(\n",
    "    y_test_us, grid_lr_us.predict_proba(X_test_us_full)[:, 1])\n",
    "\n",
    "\n",
    "# Calculating area under the curve (AUC) for ROC for US LogReg Grid\n",
    "auc_lr_us_grid = roc_auc_score(y_test_us, grid_lr_us.predict_proba(X_test_us_full)[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gridsearch SVM\n",
    "\n",
    "# EU\n",
    "\n",
    "svm_eu_grid = svm.SVC(probability=True)\n",
    "\n",
    "grid_svm_eu_values = {'C': [0.1, 1, 10, 100, 1000], \n",
    "              'gamma': [1, 0.1, 0.01, 0.001, 0.0001]} \n",
    "\n",
    "grid_svm_eu = GridSearchCV(estimator = svm_eu_grid, \n",
    "                          param_grid = grid_svm_eu_values, \n",
    "                          scoring = 'recall', \n",
    "                          cv=5, verbose=1, n_jobs=-1)\n",
    "\n",
    "grid_svm_eu.fit(X_train_eu_full, y_train_eu)\n",
    "\n",
    "print(\"EU SVM best parameters:\", grid_svm_eu.best_params_)\n",
    "\n",
    "y_pred_svm_eu_grid = grid_svm_eu.predict(X_test_eu_full)\n",
    "\n",
    "acc_svm_eu_grid = accuracy_score(y_test_eu, y_pred_svm_eu_grid)\n",
    "f1_svm_eu_grid = f1_score(y_test_eu, y_pred_svm_eu_grid)\n",
    "fb_svm_eu_grid = fbeta_score(y_test_eu, y_pred_svm_eu_grid, beta=3)\n",
    "\n",
    "print(\"SVM EU Accuracy: \", acc_svm_eu_grid)\n",
    "print(\"SVM EU f1 Score: \", f1_svm_eu_grid)\n",
    "print(\"SVM EU f-beta Score: \", fb_svm_eu_grid)\n",
    "\n",
    "# Calculating ROC curve for EU SVM Grid\n",
    "fpr_svm_eu_grid, tpr_svm_eu_grid, thresholds_svm_eu_grid = roc_curve(\n",
    "    y_test_eu, grid_svm_eu.predict_proba(X_test_eu_full)[:, 1])\n",
    "\n",
    "\n",
    "# Calculating area under the curve (AUC) for ROC for EU SVM Grid\n",
    "auc_svm_eu_grid = roc_auc_score(y_test_eu, grid_svm_eu.predict_proba(X_test_eu_full)[:, 1])\n",
    "\n",
    "\n",
    "# US\n",
    "\n",
    "svm_us_grid = svm.SVC(probability=True)\n",
    "\n",
    "grid_svm_us_values = {'C': [0.1, 1, 10, 100, 1000], \n",
    "              'gamma': [1, 0.1, 0.01, 0.001, 0.0001]} \n",
    "\n",
    "grid_svm_us = GridSearchCV(estimator = svm_us_grid, \n",
    "                          param_grid = grid_svm_us_values, \n",
    "                          scoring = 'recall', \n",
    "                          cv=5, verbose=1, n_jobs=-1)\n",
    "\n",
    "grid_svm_us.fit(X_train_us_full, y_train_us)\n",
    "\n",
    "print(\"US SVM best parameters:\", grid_svm_us.best_params_)\n",
    "\n",
    "y_pred_svm_us_grid = grid_svm_us.predict(X_test_us_full)\n",
    "\n",
    "acc_svm_us_grid = accuracy_score(y_test_us, y_pred_svm_us_grid)\n",
    "f1_svm_us_grid = f1_score(y_test_us, y_pred_svm_us_grid)\n",
    "fb_svm_us_grid = fbeta_score(y_test_us, y_pred_svm_us_grid, beta=3)\n",
    "\n",
    "print(\"SVM US Accuracy: \", acc_svm_us_grid)\n",
    "print(\"SVM US f1 Score: \", f1_svm_us_grid)\n",
    "print(\"SVM US f-beta Score: \", fb_svm_us_grid)\n",
    "\n",
    "# Calculating ROC curve for US SVM Grid\n",
    "fpr_svm_us_grid, tpr_svm_us_grid, thresholds_svm_us_grid = roc_curve(\n",
    "    y_test_us, grid_svm_us.predict_proba(X_test_us_full)[:, 1])\n",
    "\n",
    "\n",
    "# Calculating area under the curve (AUC) for ROC for US SVM Grid\n",
    "auc_svm_us_grid = roc_auc_score(y_test_us, grid_svm_us.predict_proba(X_test_us_full)[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gridsearch Random Forest\n",
    "\n",
    "# EU\n",
    "\n",
    "rf_eu_grid = RandomForestClassifier()\n",
    "\n",
    "grid_rf_eu_values = {'n_estimators': [200, 500],\n",
    "                     'max_features': ['auto', 'sqrt', 'log2'],\n",
    "                     'max_depth' : [4,5,6,7,8],\n",
    "                     'criterion' :['gini', 'entropy']} \n",
    "\n",
    "grid_rf_eu = GridSearchCV(estimator = rf_eu_grid, \n",
    "                          param_grid = grid_rf_eu_values, \n",
    "                          scoring = 'recall', \n",
    "                          cv=5, verbose=1, n_jobs=-1)\n",
    "\n",
    "grid_rf_eu.fit(X_train_eu_full, y_train_eu)\n",
    "\n",
    "print(\"EU Random Forest best parameters:\", grid_rf_eu.best_params_)\n",
    "\n",
    "y_pred_rf_eu_grid = grid_rf_eu.predict(X_test_eu_full)\n",
    "\n",
    "acc_rf_eu_grid = accuracy_score(y_test_eu, y_pred_rf_eu_grid)\n",
    "f1_rf_eu_grid = f1_score(y_test_eu, y_pred_rf_eu_grid)\n",
    "fb_rf_eu_grid = fbeta_score(y_test_eu, y_pred_rf_eu_grid, beta=3)\n",
    "\n",
    "print(\"Random Forest EU Accuracy: \", acc_rf_eu_grid)\n",
    "print(\"Random Forest EU f1 Score: \", f1_rf_eu_grid)\n",
    "print(\"Random Forest EU f-beta Score: \", fb_rf_eu_grid)\n",
    "\n",
    "# Calculating ROC curve for EU Random Forest Grid\n",
    "fpr_rf_eu_grid, tpr_rf_eu_grid, thresholds_rf_eu_grid = roc_curve(\n",
    "    y_test_eu, grid_rf_eu.predict_proba(X_test_eu_full)[:, 1])\n",
    "\n",
    "\n",
    "# Calculating area under the curve (AUC) for ROC for EU Random Forest Grid\n",
    "auc_rf_eu_grid = roc_auc_score(y_test_eu, grid_rf_eu.predict_proba(X_test_eu_full)[:, 1])\n",
    "\n",
    "\n",
    "\n",
    "# US\n",
    "\n",
    "rf_us_grid = RandomForestClassifier()\n",
    "\n",
    "grid_rf_us_values = {'n_estimators': [200, 500],\n",
    "                     'max_features': ['auto', 'sqrt', 'log2'],\n",
    "                     'max_depth' : [4,5,6,7,8],\n",
    "                     'criterion' :['gini', 'entropy']} \n",
    "\n",
    "grid_rf_us = GridSearchCV(estimator = rf_us_grid, \n",
    "                          param_grid = grid_rf_us_values, \n",
    "                          scoring = 'recall', \n",
    "                          cv=5, verbose=1, n_jobs=-1)\n",
    "\n",
    "grid_rf_us.fit(X_train_us_full, y_train_us)\n",
    "\n",
    "print(\"US Random Forest best parameters:\", grid_rf_us.best_params_)\n",
    "\n",
    "y_pred_rf_us_grid = grid_rf_us.predict(X_test_us_full)\n",
    "\n",
    "acc_rf_us_grid = accuracy_score(y_test_us, y_pred_rf_us_grid)\n",
    "f1_rf_us_grid = f1_score(y_test_us, y_pred_rf_us_grid)\n",
    "fb_rf_us_grid = fbeta_score(y_test_us, y_pred_rf_us_grid, beta=3)\n",
    "\n",
    "print(\"Random Forest US Accuracy: \", acc_rf_us_grid)\n",
    "print(\"Random Forest US f1 Score: \", f1_rf_us_grid)\n",
    "print(\"Random Forest US f-beta Score: \", fb_rf_us_grid)\n",
    "\n",
    "# Calculating ROC curve for US Random Forest Grid\n",
    "fpr_rf_us_grid, tpr_rf_us_grid, thresholds_rf_us_grid = roc_curve(\n",
    "    y_test_us, grid_rf_us.predict_proba(X_test_us_full)[:, 1])\n",
    "\n",
    "\n",
    "# Calculating area under the curve (AUC) for ROC for US Random Forest Grid\n",
    "auc_rf_us_grid = roc_auc_score(y_test_us, grid_rf_us.predict_proba(X_test_us_full)[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gridsearch XGBoost\n",
    "\n",
    "# EU\n",
    "\n",
    "xgb_eu_grid = XGBClassifier()\n",
    "\n",
    "grid_xgb_eu_values = {\"subsample\":[0.5, 0.75, 1],\n",
    "                      \"colsample_bytree\":[0.5, 0.75, 1],\n",
    "                      \"max_depth\":[2, 6, 12],\n",
    "                      \"min_child_weight\":[1, 5, 15],\n",
    "                      \"learning_rate\":[0.3, 0.1, 0.03],\n",
    "                      \"n_estimators\":[50, 100, 150, 200]} \n",
    "\n",
    "grid_xgb_eu = GridSearchCV(estimator = xgb_eu_grid, \n",
    "                          param_grid = grid_xgb_eu_values, \n",
    "                          scoring = 'recall', \n",
    "                          cv=5, verbose=1, n_jobs=-1)\n",
    "\n",
    "grid_xgb_eu.fit(X_train_eu_full, y_train_eu)\n",
    "\n",
    "print(\"EU XGBoost best parameters:\", grid_xgb_eu.best_params_)\n",
    "\n",
    "y_pred_xgb_eu_grid = grid_xgb_eu.predict(X_test_eu_full)\n",
    "\n",
    "acc_xgb_eu_grid = accuracy_score(y_test_eu, y_pred_xgb_eu_grid)\n",
    "f1_xgb_eu_grid = f1_score(y_test_eu, y_pred_xgb_eu_grid)\n",
    "fb_xgb_eu_grid = fbeta_score(y_test_eu, y_pred_xgb_eu_grid, beta=3)\n",
    "\n",
    "print(\"XGB EU Accuracy: \", acc_xgb_eu_grid)\n",
    "print(\"XGB EU f1 Score: \", f1_xgb_eu_grid)\n",
    "print(\"XGB EU f-beta Score: \", fb_xgb_eu_grid)\n",
    "\n",
    "# Calculating ROC curve for EU XGB Grid\n",
    "fpr_xgb_eu_grid, tpr_xgb_eu_grid, thresholds_xgb_eu_grid = roc_curve(\n",
    "    y_test_eu, grid_xgb_eu.predict_proba(X_test_eu_full)[:, 1])\n",
    "\n",
    "\n",
    "# Calculating area under the curve (AUC) for ROC for EU XGB Grid\n",
    "auc_xgb_eu_grid = roc_auc_score(y_test_eu, grid_xgb_eu.predict_proba(X_test_eu_full)[:, 1])\n",
    "\n",
    "\n",
    "\n",
    "# US\n",
    "\n",
    "xgb_us_grid = XGBClassifier()\n",
    "\n",
    "grid_xgb_us_values = {\"subsample\":[0.5, 0.75, 1],\n",
    "                      \"colsample_bytree\":[0.5, 0.75, 1],\n",
    "                      \"max_depth\":[2, 6, 12],\n",
    "                      \"min_child_weight\":[1, 5, 15],\n",
    "                      \"learning_rate\":[0.3, 0.1, 0.03],\n",
    "                      \"n_estimators\":[50, 100, 150, 200]} \n",
    "\n",
    "grid_xgb_us = GridSearchCV(estimator = xgb_us_grid, \n",
    "                          param_grid = grid_xgb_us_values, \n",
    "                          scoring = 'recall', \n",
    "                          cv=5, verbose=1, n_jobs=-1)\n",
    "\n",
    "grid_xgb_us.fit(X_train_us_full, y_train_us)\n",
    "\n",
    "print(\"US XGBoost best parameters:\", grid_xgb_us.best_params_)\n",
    "\n",
    "y_pred_xgb_us_grid = grid_xgb_us.predict(X_test_us_full)\n",
    "\n",
    "acc_xgb_us_grid = accuracy_score(y_test_us, y_pred_xgb_us_grid)\n",
    "f1_xgb_us_grid = f1_score(y_test_us, y_pred_xgb_us_grid)\n",
    "fb_xgb_us_grid = fbeta_score(y_test_us, y_pred_xgb_us_grid, beta=3)\n",
    "\n",
    "print(\"XGB US Accuracy: \", acc_xgb_us_grid)\n",
    "print(\"XGB US f1 Score: \", f1_xgb_us_grid)\n",
    "print(\"XGB US f-beta Score: \", fb_xgb_us_grid)\n",
    "\n",
    "# Calculating ROC curve for US XGB Grid\n",
    "fpr_xgb_us_grid, tpr_xgb_us_grid, thresholds_xgb_us_grid = roc_curve(\n",
    "    y_test_us, grid_xgb_us.predict_proba(X_test_us_full)[:, 1])\n",
    "\n",
    "\n",
    "# Calculating area under the curve (AUC) for ROC for US XGB Grid\n",
    "auc_xgb_us_grid = roc_auc_score(y_test_us, grid_xgb_us.predict_proba(X_test_us_full)[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gridsearch Multilayer Perceptron\n",
    "\n",
    "# EU\n",
    "\n",
    "mlp_eu_grid = MLPClassifier()\n",
    "\n",
    "grid_mlp_eu_values = {'hidden_layer_sizes': [(50,50,50), (50,100,50), (100,)],\n",
    "                      'solver': ['sgd', 'adam'],\n",
    "                      'activation': ['relu', 'tanh', 'logistic'],\n",
    "                      'alpha': [0.0001, 0.05],\n",
    "                      'learning_rate': ['constant','adaptive'],} \n",
    "\n",
    "grid_mlp_eu = GridSearchCV(estimator = mlp_eu_grid, \n",
    "                          param_grid = grid_mlp_eu_values, \n",
    "                          scoring = 'recall', \n",
    "                          cv=5, verbose=1, n_jobs=-1)\n",
    "\n",
    "grid_mlp_eu.fit(X_train_eu_full, y_train_eu)\n",
    "\n",
    "print(\"EU Multilayer Perceptron best parameters:\", grid_mlp_eu.best_params_)\n",
    "\n",
    "y_pred_mlp_eu_grid = grid_mlp_eu.predict(X_test_eu_full)\n",
    "\n",
    "acc_mlp_eu_grid = accuracy_score(y_test_eu, y_pred_mlp_eu_grid)\n",
    "f1_mlp_eu_grid = f1_score(y_test_eu, y_pred_mlp_eu_grid)\n",
    "fb_mlp_eu_grid = fbeta_score(y_test_eu, y_pred_mlp_eu_grid, beta=3)\n",
    "\n",
    "print(\"MLP EU Accuracy: \", acc_mlp_eu_grid)\n",
    "print(\"MLP EU f1 Score: \", f1_mlp_eu_grid)\n",
    "print(\"MLP EU f-beta Score: \", fb_mlp_eu_grid)\n",
    "\n",
    "# Calculating ROC curve for EU MLP Grid\n",
    "fpr_mlp_eu_grid, tpr_mlp_eu_grid, thresholds_mlp_eu_grid = roc_curve(\n",
    "    y_test_eu, grid_mlp_eu.predict_proba(X_test_eu_full)[:, 1])\n",
    "\n",
    "\n",
    "# Calculating area under the curve (AUC) for ROC for EU MLP Grid\n",
    "auc_mlp_eu_grid = roc_auc_score(y_test_eu, grid_mlp_eu.predict_proba(X_test_eu_full)[:, 1])\n",
    "\n",
    "\n",
    "# US\n",
    "\n",
    "mlp_us_grid = MLPClassifier()\n",
    "\n",
    "grid_mlp_us_values = {'hidden_layer_sizes': [(50,50,50), (50,100,50), (100,)],\n",
    "                      'solver': ['sgd', 'adam'],\n",
    "                      'activation': ['relu', 'tanh', 'logistic'],\n",
    "                      'alpha': [0.0001, 0.05],\n",
    "                      'learning_rate': ['constant','adaptive'],} \n",
    "\n",
    "grid_mlp_us = GridSearchCV(estimator = mlp_us_grid, \n",
    "                          param_grid = grid_mlp_us_values, \n",
    "                          scoring = 'recall', \n",
    "                          cv=5, verbose=1, n_jobs=-1)\n",
    "\n",
    "grid_mlp_us.fit(X_train_us_full, y_train_us)\n",
    "\n",
    "print(\"US Multilayer Perceptron best parameters:\", grid_mlp_us.best_params_)\n",
    "\n",
    "y_pred_mlp_us_grid = grid_mlp_us.predict(X_test_us_full)\n",
    "\n",
    "acc_mlp_us_grid = accuracy_score(y_test_us, y_pred_mlp_us_grid)\n",
    "f1_mlp_us_grid = f1_score(y_test_us, y_pred_mlp_us_grid)\n",
    "fb_mlp_us_grid = fbeta_score(y_test_us, y_pred_mlp_us_grid, beta=3)\n",
    "\n",
    "print(\"MLP US Accuracy: \", acc_mlp_us_grid)\n",
    "print(\"MLP US f1 Score: \", f1_mlp_us_grid)\n",
    "print(\"MLP US f-beta Score: \", fb_mlp_us_grid)\n",
    "\n",
    "# Calculating ROC curve for US MLP Grid\n",
    "fpr_mlp_us_grid, tpr_mlp_us_grid, thresholds_mlp_us_grid = roc_curve(\n",
    "    y_test_us, grid_mlp_us.predict_proba(X_test_us_full)[:, 1])\n",
    "\n",
    "\n",
    "# Calculating area under the curve (AUC) for ROC for US MLP Grid\n",
    "auc_mlp_us_grid = roc_auc_score(y_test_us, grid_mlp_us.predict_proba(X_test_us_full)[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression\n",
    "\n",
    "# Instantiate EU model\n",
    "lr_eu = LogisticRegression(C=0.01, penalty=\"l2\", solver='lbfgs')\n",
    "\n",
    "# Fit model to the EU training data\n",
    "lr_eu.fit(X_train_eu_full, y_train_eu)\n",
    "\n",
    "# Predicting and calculating accuracy, f1 and f-beta score\n",
    "y_pred_lr_eu = lr_eu.predict(X_test_eu_full)\n",
    "acc_lr_eu = accuracy_score(y_test_eu, y_pred_lr_eu)\n",
    "\n",
    "f1_lr_eu = f1_score(y_test_eu, y_pred_lr_eu)\n",
    "fb_lr_eu = fbeta_score(y_test_eu, y_pred_lr_eu, beta=3)\n",
    "\n",
    "print(\"Logistic Regression EU Accuracy: \", acc_lr_eu)\n",
    "print(\"Logistic Regression EU f1 Score: \", f1_lr_eu)\n",
    "print(\"Logistic Regression EU f-beta Score: \", fb_lr_eu)\n",
    "\n",
    "# Calculating ROC curve for EU LogReg\n",
    "fpr_lr_eu, tpr_lr_eu, thresholds_lr_eu = roc_curve(\n",
    "    y_test_eu, lr_eu.predict_proba(X_test_eu_full)[:, 1])\n",
    "\n",
    "# Calculating area under the curve (AUC) for ROC for EU LogReg\n",
    "auc_lr_eu = roc_auc_score(y_test_eu, lr_eu.predict_proba(X_test_eu_full)[:, 1])\n",
    "\n",
    " \n",
    "\n",
    "    \n",
    "# Instantiate US model\n",
    "lr_us = LogisticRegression(C=0.01, penalty = 'l2', solver='lbfgs')\n",
    "\n",
    "# Fit model to the US training data\n",
    "lr_us.fit(X_train_us_full, y_train_us)\n",
    "\n",
    "# Predicting and calculating accuracy and f1 score\n",
    "y_pred_lr_us = lr_us.predict(X_test_us_full)\n",
    "acc_lr_us = accuracy_score(y_test_us, y_pred_lr_us)\n",
    "\n",
    "f1_lr_us = f1_score(y_test_us, y_pred_lr_us)\n",
    "fb_lr_us = fbeta_score(y_test_us, y_pred_lr_us, beta=3)\n",
    "\n",
    "print(\"\\nLogistic Regression US Accuracy: \", acc_lr_us)\n",
    "print(\"Logistic Regression US f1 Score: \", f1_lr_us)\n",
    "print(\"Logistic Regression US f-beta Score: \", fb_lr_us)\n",
    "\n",
    "# Calculating ROC curve for US LogReg\n",
    "fpr_lr_us, tpr_lr_us, thresholds_lr_us = roc_curve(\n",
    "    y_test_us, lr_us.predict_proba(X_test_us_full)[:, 1])\n",
    "\n",
    "# Calculating area under the curve (AUC) for ROC for US LogReg\n",
    "auc_lr_us = roc_auc_score(y_test_us, lr_us.predict_proba(X_test_us_full)[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Support Vector Machine (SVM)\n",
    "\n",
    "# EU\n",
    "\n",
    "svm_eu = svm.SVC(C=0.1,\n",
    "                 gamma=1,\n",
    "                 kernel=\"linear\", \n",
    "                 probability=True)\n",
    "\n",
    "svm_eu.fit(X_train_eu_full, y_train_eu)\n",
    "\n",
    "# Predicting and calculating accuracy and f1 score\n",
    "y_pred_svm_eu = svm_eu.predict(X_test_eu_full)\n",
    "acc_svm_eu = accuracy_score(y_test_eu, y_pred_svm_eu)\n",
    "\n",
    "f1_svm_eu = f1_score(y_test_eu, y_pred_svm_eu)\n",
    "fb_svm_eu = fbeta_score(y_test_eu, y_pred_svm_eu, beta=3)\n",
    "\n",
    "\n",
    "print(\"SVM EU Accuracy: \", acc_svm_eu)\n",
    "print(\"SVM EU f1 Score: \", f1_svm_eu)\n",
    "print(\"SVM EU f-beta Score: \", fb_svm_eu)\n",
    "\n",
    "# Calculating ROC curve for EU SVM\n",
    "fpr_svm_eu, tpr_svm_eu, thresholds_svm_eu = roc_curve(\n",
    "    y_test_eu, svm_eu.predict_proba(X_test_eu_full)[:, 1])\n",
    "\n",
    "# Calculating area under the curve (AUC) for ROC for EU SVM\n",
    "auc_svm_eu = roc_auc_score(y_test_eu, svm_eu.predict_proba(X_test_eu_full)[:, 1])\n",
    "\n",
    "\n",
    "# US\n",
    "\n",
    "svm_us = svm.SVC(C=0.1,\n",
    "                 gamma=1,\n",
    "                 kernel=\"linear\", \n",
    "                 probability=True)\n",
    "\n",
    "svm_us.fit(X_train_us_full, y_train_us)\n",
    "\n",
    "# Predicting and calculating accuracy and f1 score\n",
    "y_pred_svm_us = svm_us.predict(X_test_us_full)\n",
    "acc_svm_us = accuracy_score(y_test_us, y_pred_svm_us)\n",
    "\n",
    "f1_svm_us = f1_score(y_test_us, y_pred_svm_us)\n",
    "fb_svm_us = fbeta_score(y_test_us, y_pred_svm_us, beta=3)\n",
    "\n",
    "print(\"\\nSVM US Accuracy: \", acc_svm_us)\n",
    "print(\"SVM US f1 Score: \", f1_svm_us)\n",
    "print(\"SVM US f-beta Score: \", fb_svm_us)\n",
    "\n",
    "# Calculating ROC curve for US SVM\n",
    "fpr_svm_us, tpr_svm_us, thresholds_svm_us = roc_curve(\n",
    "    y_test_us, svm_us.predict_proba(X_test_us_full)[:, 1])\n",
    "\n",
    "# Calculating area under the curve (AUC) for ROC for US SVM\n",
    "auc_svm_us = roc_auc_score(y_test_us, svm_us.predict_proba(X_test_us_full)[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest\n",
    "\n",
    "# EU\n",
    "rf_eu = RandomForestClassifier(n_estimators=200,\n",
    "                               max_features='log2',\n",
    "                               max_depth=8,\n",
    "                               criterion='gini',\n",
    "                               bootstrap=True,\n",
    "                               oob_score=True,\n",
    "                               random_state=42,\n",
    "                               n_jobs=-1)\n",
    "\n",
    "rf_eu.fit(X_train_eu_full, y_train_eu)\n",
    "\n",
    "# Predicting and calculating accuracy and f1 score\n",
    "y_pred_rf_eu = rf_eu.predict(X_test_eu_full)\n",
    "acc_rf_eu = accuracy_score(y_test_eu, y_pred_rf_eu)\n",
    "\n",
    "f1_rf_eu = f1_score(y_test_eu, y_pred_rf_eu)\n",
    "fb_rf_eu = fbeta_score(y_test_eu, y_pred_rf_eu, beta=3)\n",
    "\n",
    "print(\"Random Forest EU Accuracy: \", acc_rf_eu)\n",
    "print(\"Random Forest EU f1 Score: \", f1_rf_eu)\n",
    "print(\"Random Forest EU f-beta Score: \", fb_rf_eu)\n",
    "\n",
    "# Calculating ROC curve for EU Random Forest\n",
    "fpr_rf_eu, tpr_rf_eu, thresholds_rf_eu = roc_curve(\n",
    "    y_test_eu, rf_eu.predict_proba(X_test_eu_full)[:, 1])\n",
    "\n",
    "# Calculating area under the curve (AUC) for ROC for EU Random Forest\n",
    "auc_rf_eu = roc_auc_score(y_test_eu, rf_eu.predict_proba(X_test_eu_full)[:, 1])\n",
    "\n",
    "\n",
    "# US\n",
    "rf_us = RandomForestClassifier(n_estimators=200,\n",
    "                               max_features='log2',\n",
    "                               max_depth=7,\n",
    "                               criterion='gini',\n",
    "                               bootstrap=True,\n",
    "                               oob_score=True,\n",
    "                               random_state=42,\n",
    "                               n_jobs=-1)\n",
    "\n",
    "rf_us.fit(X_train_us_full, y_train_us)\n",
    "\n",
    "# Predicting and calculating accuracy and f1 score\n",
    "y_pred_rf_us = rf_us.predict(X_test_us_full)\n",
    "acc_rf_us = accuracy_score(y_test_us, y_pred_rf_us)\n",
    "\n",
    "f1_rf_us = f1_score(y_test_us, y_pred_rf_us)\n",
    "fb_rf_us = fbeta_score(y_test_us, y_pred_rf_us, beta=3)\n",
    "\n",
    "print(\"\\nRandom Forest US Accuracy: \", acc_rf_us)\n",
    "print(\"Random Forest US f1 Score: \", f1_rf_us)\n",
    "print(\"Random Forest US f-beta Score: \", fb_rf_us)\n",
    "\n",
    "# Calculating ROC curve for US Random Forest\n",
    "fpr_rf_us, tpr_rf_us, thresholds_rf_us = roc_curve(\n",
    "    y_test_us, rf_us.predict_proba(X_test_us_full)[:, 1])\n",
    "\n",
    "# Calculating area under the curve (AUC) for ROC for US Random Forest\n",
    "auc_rf_us = roc_auc_score(y_test_us, rf_us.predict_proba(X_test_us_full)[:, 1])\n",
    "\n",
    "\n",
    "'''\n",
    "# Feature importance\n",
    "\n",
    "rf_eu_featuress = pd.DataFrame({\n",
    "    'feature': X_eu.columns,\n",
    "    'importance': rf_eu.feature_importances_\n",
    "}).sort_values(by='importance', ascending=False)\n",
    "\n",
    "# Look at top 10 features\n",
    "rf_eu_featuress[0:10]\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost\n",
    "\n",
    "# EU\n",
    "xgb_eu = XGBClassifier(colsample_bytree=0.75, \n",
    "                       learning_rate=0.1,\n",
    "                       max_depth=12, \n",
    "                       min_child_weight=1,\n",
    "                       n_estimators=100,\n",
    "                       subsample=1)\n",
    "\n",
    "xgb_eu.fit(X_train_eu_full, y_train_eu)\n",
    "\n",
    "# Predicting and calculating accuracy and f1 score\n",
    "y_pred_xgb_eu = xgb_eu.predict(X_test_eu_full)\n",
    "acc_xgb_eu = accuracy_score(y_test_eu, y_pred_xgb_eu)\n",
    "\n",
    "f1_xgb_eu = f1_score(y_test_eu, y_pred_xgb_eu)\n",
    "fb_xgb_eu = fbeta_score(y_test_eu, y_pred_xgb_eu, beta=3)\n",
    "\n",
    "print(\"XGBoost EU Accuracy: \", acc_xgb_eu)\n",
    "print(\"XGBoost EU f1 Score: \", f1_xgb_eu)\n",
    "print(\"XGBoost EU f-beta Score: \", fb_xgb_eu)\n",
    "\n",
    "# Calculating ROC curve for EU XGBoost\n",
    "fpr_xgb_eu, tpr_xgb_eu, thresholds_xgb_eu = roc_curve(\n",
    "    y_test_eu, xgb_eu.predict_proba(X_test_eu_full)[:, 1])\n",
    "\n",
    "# Calculating area under the curve (AUC) for ROC for EU XGBoost\n",
    "auc_xgb_eu = roc_auc_score(y_test_eu, xgb_eu.predict_proba(X_test_eu_full)[:, 1])\n",
    "\n",
    "\n",
    "# US\n",
    "xgb_us = XGBClassifier(colsample_bytree=0.5, \n",
    "                       learning_rate=0.3,\n",
    "                       max_depth=6, \n",
    "                       min_child_weight=1,\n",
    "                       n_estimators=100,\n",
    "                       subsample=1)\n",
    "\n",
    "xgb_us.fit(X_train_us_full, y_train_us)\n",
    "\n",
    "# Predicting and calculating accuracy and f1 score\n",
    "y_pred_xgb_us = xgb_us.predict(X_test_us_full)\n",
    "acc_xgb_us = accuracy_score(y_test_us, y_pred_xgb_us)\n",
    "\n",
    "f1_xgb_us = f1_score(y_test_us, y_pred_xgb_us)\n",
    "fb_xgb_us = fbeta_score(y_test_us, y_pred_xgb_us, beta=3)\n",
    "\n",
    "print(\"\\nXGBoost US Accuracy: \", acc_xgb_us)\n",
    "print(\"XGBoost US f1 Score: \", f1_xgb_us)\n",
    "print(\"XGBoost US f-beta Score: \", fb_xgb_us)\n",
    "\n",
    "# Calculating ROC curve for US XGBoost\n",
    "fpr_xgb_us, tpr_xgb_us, thresholds_xgb_us = roc_curve(\n",
    "    y_test_us, xgb_us.predict_proba(X_test_us_full)[:, 1])\n",
    "\n",
    "# Calculating area under the curve (AUC) for ROC for US XGBoost\n",
    "auc_xgb_us = roc_auc_score(y_test_us, xgb_us.predict_proba(X_test_us_full)[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multilayer Perceptron EU\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "mlp_eu = MLPClassifier(\n",
    "    hidden_layer_sizes=(50, 50, 50),\n",
    "    activation='relu',\n",
    "    alpha=0.05,\n",
    "    solver=\"adam\",\n",
    "    verbose=False,\n",
    "    random_state=42,\n",
    "    learning_rate='constant'\n",
    ")\n",
    "\n",
    "mlp_eu.fit(X_train_eu_full, y_train_eu)\n",
    "\n",
    "y_pred_mlp_eu = mlp_eu.predict(X_test_eu_full)\n",
    "acc_mlp_eu = accuracy_score(y_test_eu, y_pred_mlp_eu)\n",
    "f1_mlp_eu = f1_score(y_test_eu, y_pred_mlp_eu)\n",
    "fb_mlp_eu = fbeta_score(y_test_eu, y_pred_mlp_eu, beta=3)\n",
    "\n",
    "print(\"MLP EU Accuracy: \", acc_mlp_eu)\n",
    "print(\"MLP EU f1 Score: \", f1_mlp_eu)\n",
    "print(\"MLP EU f-beta Score: \", fb_mlp_eu)\n",
    "\n",
    "# Calculating ROC curve for EU MLP\n",
    "fpr_mlp_eu, tpr_mlp_eu, thresholds_mlp_eu = roc_curve(\n",
    "    y_test_eu, mlp_eu.predict_proba(X_test_eu_full)[:, 1])\n",
    "\n",
    "# Calculating area under the curve (AUC) for ROC for EU MLP\n",
    "auc_mlp_eu = roc_auc_score(y_test_eu, mlp_eu.predict_proba(X_test_eu_full)[:, 1])\n",
    "\n",
    "\n",
    "# US\n",
    "mlp_us = MLPClassifier(\n",
    "    hidden_layer_sizes=(50, 50, 50),\n",
    "    activation='relu',\n",
    "    alpha=0.001,\n",
    "    solver=\"sgd\",\n",
    "    verbose=False,\n",
    "    random_state=1,\n",
    "    learning_rate='constant'\n",
    ")\n",
    "\n",
    "mlp_us.fit(X_train_us_full, y_train_us)\n",
    "\n",
    "y_pred_mlp_us = mlp_us.predict(X_test_us_full)\n",
    "acc_mlp_us = accuracy_score(y_test_us, y_pred_mlp_us)\n",
    "f1_mlp_us = f1_score(y_test_us, y_pred_mlp_us)\n",
    "fb_mlp_us = fbeta_score(y_test_us, y_pred_mlp_us, beta=3)\n",
    "\n",
    "print(\"\\nMLP US Accuracy: \", acc_mlp_us)\n",
    "print(\"MLP US f1 Score: \", f1_mlp_us)\n",
    "print(\"MLP US f-beta Score: \", fb_mlp_us)\n",
    "\n",
    "# Calculating ROC curve for EU MLP\n",
    "fpr_mlp_us, tpr_mlp_us, thresholds_mlp_us = roc_curve(\n",
    "    y_test_us, mlp_us.predict_proba(X_test_us_full)[:, 1])\n",
    "\n",
    "# Calculating area under the curve (AUC) for ROC for US MLP\n",
    "auc_mlp_us = roc_auc_score(y_test_us, mlp_us.predict_proba(X_test_us_full)[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Comparison Accuracy, f1 scores and ROC/AUC\n",
    "\n",
    "# EU\n",
    "clfs_eu = [\"lr\", \"svm\", \"rf\", \"xgb\", \"mlp\"]\n",
    "\n",
    "model_aucs_eu = [\n",
    "    auc_lr_eu_grid, auc_svm_eu_grid, auc_rf_eu_grid, auc_xgb_eu_grid, auc_mlp_eu_grid]\n",
    "\n",
    "model_acc_eu = [\n",
    "    acc_lr_eu_grid, acc_svm_eu_grid, acc_rf_eu_grid, acc_xgb_eu_grid, acc_mlp_eu_grid]\n",
    "\n",
    "model_f1_eu = [\n",
    "    f1_lr_eu_grid, f1_svm_eu_grid, f1_rf_eu_grid, f1_xgb_eu_grid, f1_mlp_eu_grid]\n",
    "\n",
    "model_fb_eu = [\n",
    "    fb_lr_eu_grid, fb_svm_eu_grid, fb_rf_eu_grid, fb_xgb_eu_grid, fb_mlp_eu_grid]\n",
    "\n",
    "model_names = [\n",
    "    \"Logistic Regression\", \"Support Vector Machine\", \"Random Forest\", \"XGBoost\", \"Multilayer Perceptron\"]\n",
    "\n",
    "\n",
    "# US\n",
    "clfs_us = [\"lr\", \"svm\", \"rf\", \"xgb\", \"mlp\"]\n",
    "model_aucs_us = [\n",
    "    auc_lr_us_grid, auc_svm_us_grid, auc_rf_us_grid, auc_xgb_us_grid, auc_mlp_us_grid]\n",
    "\n",
    "model_acc_us = [\n",
    "    acc_lr_us_grid, acc_svm_us_grid, acc_rf_us_grid, acc_xgb_us_grid, acc_mlp_us_grid]\n",
    "\n",
    "model_f1_us = [\n",
    "    f1_lr_us_grid, f1_svm_us_grid, f1_rf_us_grid, f1_xgb_us_grid, f1_mlp_us_grid]\n",
    "\n",
    "model_fb_us = [\n",
    "    fb_lr_us_grid, fb_svm_us_grid, fb_rf_us_grid, fb_xgb_us_grid, fb_mlp_us_grid]\n",
    "\n",
    "model_names = [\n",
    "    \"Logistic Regression\", \"Support Vector Machine\", \"Random Forest\", \"XGBoost\", \"Multilayer Perceptron\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting ROC Curves\n",
    "\n",
    "# EU\n",
    "plt.plot(fpr_lr_eu_grid, tpr_lr_eu_grid, lw=1, label=\"Logistic Regression\")\n",
    "plt.plot(fpr_svm_eu_grid, tpr_svm_eu_grid, lw=1, label=\"SVM - Linear\")\n",
    "plt.plot(fpr_rf_eu_grid, tpr_rf_eu_grid, lw=1, label=\"Random Forest\")\n",
    "plt.plot(fpr_xgb_eu_grid, tpr_xgb_eu_grid, lw=1, label=\"XGBoost\")\n",
    "plt.plot(fpr_mlp_eu_grid, tpr_mlp_eu_grid, lw=1, label=\"Multilayer Perceptron\")\n",
    "\n",
    "\n",
    "plt.plot([0, 1], [0, 1], c='violet', ls='--')\n",
    "plt.xlim([-0.05, 1.05])\n",
    "plt.ylim([-0.05, 1.05])\n",
    "\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.title('EU Model Comparison - ROC curve')\n",
    "plt.legend(ncol=2, fontsize='small')\n",
    "sns.despine()\n",
    "\n",
    "# Print EU AUC Scores\n",
    "for model in list(zip(model_names, model_aucs_eu)):\n",
    "    print(\"EU ROC AUC score = {:3f} for {}\".format(model[1], model[0]))\n",
    "print(\"\\n\")\n",
    "    \n",
    "# Print EU Accuracy Scores\n",
    "for model in list(zip(model_names, model_acc_eu)):\n",
    "    print(\"EU Accuracy score = {:3f} for {}\".format(model[1], model[0]))\n",
    "print(\"\\n\")\n",
    "\n",
    "# Print EU f1 Scores\n",
    "for model in list(zip(model_names, model_f1_eu)):\n",
    "    print(\"EU f1 score = {:3f} for {}\".format(model[1], model[0]))\n",
    "print(\"\\n\")\n",
    "\n",
    "# Print EU f-beta Scores\n",
    "for model in list(zip(model_names, model_fb_eu)):\n",
    "    print(\"EU f-beta score = {:3f} for {}\".format(model[1], model[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting ROC Curves\n",
    "\n",
    "# US\n",
    "plt.plot(fpr_lr_us_grid, tpr_lr_us_grid, lw=1, label=\"Logistic Regression\")\n",
    "plt.plot(fpr_svm_us_grid, tpr_svm_us_grid, lw=1, label=\"SVM - Linear\")\n",
    "plt.plot(fpr_rf_us_grid, tpr_rf_us_grid, lw=1, label=\"Random Forest\")\n",
    "plt.plot(fpr_xgb_us_grid, tpr_xgb_us_grid, lw=1, label=\"XGBoost\")\n",
    "plt.plot(fpr_mlp_us_grid, tpr_mlp_us_grid, lw=1, label=\"Multilayer Perceptron\")\n",
    "\n",
    "plt.plot([0, 1], [0, 1], c='violet', ls='--')\n",
    "plt.xlim([-0.05, 1.05])\n",
    "plt.ylim([-0.05, 1.05])\n",
    "\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.title('US Model Comparison - ROC curve')\n",
    "plt.legend(ncol=2, fontsize='small')\n",
    "sns.despine()\n",
    "\n",
    "# Print US AUC Scores\n",
    "for model in list(zip(model_names, model_aucs_us)):\n",
    "    print(\"US ROC AUC score = {:3f} for {}\".format(model[1], model[0])) \n",
    "print(\"\\n\")\n",
    "    \n",
    "# Print US Accuracy Scores\n",
    "for model in list(zip(model_names, model_acc_us)):\n",
    "    print(\"US Accuracy score = {:3f} for {}\".format(model[1], model[0]))\n",
    "print(\"\\n\")\n",
    "\n",
    "# Print US f1 Scores\n",
    "for model in list(zip(model_names, model_f1_us)):\n",
    "    print(\"US f1 score = {:3f} for {}\".format(model[1], model[0]))\n",
    "print(\"\\n\")\n",
    "    \n",
    "# Print US f-beta Scores\n",
    "for model in list(zip(model_names, model_fb_us)):\n",
    "    print(\"US f-beta score = {:3f} for {}\".format(model[1], model[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at LogReg Coefficients\n",
    "best_log_eu = grid_lr_eu.best_estimator_\n",
    "\n",
    "# EU\n",
    "lr_eu_coefs = pd.DataFrame(sorted(list(zip(X_train_eu.columns, best_log_eu.coef_[0])),\n",
    "                                   key=(lambda x: x[1]),\n",
    "                                   reverse=True),\n",
    "                            columns=['Feature', 'Coefficient'])\n",
    "lr_eu_coefs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#US Coefficients\n",
    "\n",
    "best_log_us = grid_lr_us.best_estimator_\n",
    "\n",
    "lr_us_coefs = pd.DataFrame(sorted(list(zip(X_train_us.columns, best_log_us.coef_[0])),\n",
    "                                   key=(lambda x: x[1]),\n",
    "                                   reverse=True),\n",
    "                            columns=['Feature', 'Coefficient'])\n",
    "lr_us_coefs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EU Intercept\n",
    "\n",
    "grid_lr_eu.intercept_[0]\n",
    "\n",
    "# convert intercept log-odds to probability\n",
    "logodds = grid_lr_eu.intercept_\n",
    "odds = np.exp(logodds)\n",
    "prob = odds / (1 + odds)\n",
    "prob[0]\n",
    "print(\n",
    "    'All else considered, companies that make it past their\\\n",
    "    first funding round, probability of success is {:.2f}%'\n",
    "    .format(100 * prob[0]))\n",
    "\n",
    "\n",
    "# US Intercept\n",
    "grid_lr_us.intercept_[0]\n",
    "\n",
    "# convert intercept log-odds to probability\n",
    "logodds = grid_lr_us.intercept_\n",
    "odds = np.exp(logodds)\n",
    "prob = odds / (1 + odds)\n",
    "prob[0]\n",
    "print(\n",
    "    'All else considered, companies that make it past their\\\n",
    "    first funding round, probability of success is {:.2f}%'\n",
    "    .format(100 * prob[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Confusing Matrix LogReg EU\n",
    "conf_lr_eu = confusion_matrix(y_test_eu, y_pred_lr_eu_grid)\n",
    "conf_lr_eu_show = ConfusionMatrixDisplay(confusion_matrix=conf_lr_eu)\n",
    "conf_lr_eu_show.plot()\n",
    "plt.title(\"LogReg EU\")\n",
    "plt.show()\n",
    "\n",
    "# EU LogReg Classification report\n",
    "print(classification_report(y_test_eu, y_pred_lr_eu_grid))\n",
    "\n",
    "#Confusing Matrix LogReg US\n",
    "conf_lr_us = confusion_matrix(y_test_us, y_pred_lr_us_grid)\n",
    "conf_lr_us_show = ConfusionMatrixDisplay(confusion_matrix=conf_lr_us)\n",
    "conf_lr_us_show.plot()\n",
    "plt.title(\"LogReg US\")\n",
    "plt.show()\n",
    "\n",
    "# US LogReg Classification report\n",
    "print(classification_report(y_test_us, y_pred_lr_us_grid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Confusing Matrix SVM EU\n",
    "conf_svm_eu = confusion_matrix(y_test_eu, y_pred_svm_eu_grid)\n",
    "conf_svm_eu_show = ConfusionMatrixDisplay(confusion_matrix=conf_svm_eu)\n",
    "conf_svm_eu_show.plot()\n",
    "plt.title(\"SVM EU\")\n",
    "plt.show()\n",
    "\n",
    "# EU SVM Classification report\n",
    "print(classification_report(y_test_eu, y_pred_svm_eu_grid))\n",
    "\n",
    "#Confusing Matrix SVM US\n",
    "conf_svm_us = confusion_matrix(y_test_us, y_pred_svm_us_grid)\n",
    "conf_svm_us_show = ConfusionMatrixDisplay(confusion_matrix=conf_svm_us)\n",
    "conf_svm_us_show.plot()\n",
    "plt.title(\"SVM US\")\n",
    "plt.show()\n",
    "\n",
    "# US SVM Classification report\n",
    "print(classification_report(y_test_us, y_pred_svm_us_grid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Confusing Matrix Random Forest EU\n",
    "conf_rf_eu = confusion_matrix(y_test_eu, y_pred_rf_eu_grid)\n",
    "conf_rf_eu_show = ConfusionMatrixDisplay(confusion_matrix=conf_rf_eu)\n",
    "conf_rf_eu_show.plot()\n",
    "plt.title(\"Random Forest EU\")\n",
    "plt.show()\n",
    "\n",
    "# EU Random Forest Classification report\n",
    "print(classification_report(y_test_eu, y_pred_rf_eu_grid))\n",
    "\n",
    "#Confusing Matrix Random Forest US\n",
    "conf_rf_us = confusion_matrix(y_test_us, y_pred_rf_us_grid)\n",
    "conf_rf_us_show = ConfusionMatrixDisplay(confusion_matrix=conf_rf_us)\n",
    "conf_rf_us_show.plot()\n",
    "plt.title(\"Random Forest US\")\n",
    "plt.show()\n",
    "\n",
    "# US Random Forest Classification report\n",
    "print(classification_report(y_test_us, y_pred_rf_us_grid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Confusing Matrix XGBoost EU\n",
    "conf_xgb_eu = confusion_matrix(y_test_eu, y_pred_xgb_eu_grid)\n",
    "conf_xgb_eu_show = ConfusionMatrixDisplay(confusion_matrix=conf_xgb_eu)\n",
    "conf_xgb_eu_show.plot()\n",
    "plt.title(\"XGBoost EU\")\n",
    "plt.show()\n",
    "\n",
    "# EU XGBoost Classification report\n",
    "print(classification_report(y_test_eu, y_pred_xgb_eu_grid))\n",
    "\n",
    "#Confusing Matrix XGBoost US\n",
    "conf_xgb_us = confusion_matrix(y_test_us, y_pred_xgb_us_grid)\n",
    "conf_xgb_us_show = ConfusionMatrixDisplay(confusion_matrix=conf_xgb_us)\n",
    "conf_xgb_us_show.plot()\n",
    "\n",
    "plt.title(\"XGBoost US\")\n",
    "plt.show()\n",
    "\n",
    "# US XGBoost Classification report\n",
    "print(classification_report(y_test_us, y_pred_xgb_us_grid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Confusing Matrix Multilayer Perceptron EU\n",
    "conf_mlp_eu = confusion_matrix(y_test_eu, y_pred_mlp_eu_grid)\n",
    "conf_mlp_eu_show = ConfusionMatrixDisplay(confusion_matrix=conf_mlp_eu)\n",
    "conf_mlp_eu_show.plot()\n",
    "plt.title(\"Multilayer Perceptron EU\")\n",
    "plt.show()\n",
    "\n",
    "# EU MLP Classification report\n",
    "print(classification_report(y_test_eu, y_pred_mlp_eu_grid))\n",
    "\n",
    "#Confusing Matrix Multilayer Perceptron US\n",
    "conf_mlp_us = confusion_matrix(y_test_us, y_pred_mlp_us_grid)\n",
    "conf_mlp_us_show = ConfusionMatrixDisplay(confusion_matrix=conf_mlp_us)\n",
    "conf_mlp_us_show.plot()\n",
    "plt.title(\"Multilayer Perceptron US\")\n",
    "plt.show()\n",
    "\n",
    "# US MLP Classification report\n",
    "print(classification_report(y_test_us, y_pred_mlp_us_grid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Importance XGBoost\n",
    "# XGBoost\n",
    "# eu\n",
    "'''xgb_eu_feats = pd.DataFrame({\n",
    "    'feature': X_eu.columns,\n",
    "    'importance': xgb_eu.feature_importances_\n",
    "}).sort_values(by='importance', ascending=False)\n",
    "\n",
    "# Look at top 10 features\n",
    "print(\"Feature Importance XGBoost top 10 EU: \")\n",
    "xgb_eu_feats[0:10]'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''#xgb_eu.get_booster().get_score(importance_type=\"gain\")\n",
    "\n",
    "sorted_idx = np.argsort(xgb_eu.feature_importances_)[::-1]\n",
    "\n",
    "for index in sorted_idx:\n",
    "    print([X_train_eu_full.columns[index], xgb_eu.feature_importances_[index]]) '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''import matplotlib.pyplot as plt\n",
    "\n",
    "plot_importance(xgb_eu, max_num_features = 15)\n",
    "plt.show()'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
